{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import wandb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ada9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "        print(\"GPU is not available, using CPU.\")\n",
    "        \n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"3aaf9f796df65417b3f5f8560b43875171b55805\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9528ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Sine Wave\n",
    "steps = np.linspace(0, 100, 1000)\n",
    "data = np.sin(steps)\n",
    "\n",
    "# Create sequences: use 20 points to predict the 21st\n",
    "seq_len = 20\n",
    "X, Y = [], []\n",
    "for i in range(len(data) - seq_len):\n",
    "    X.append(data[i : i + seq_len])\n",
    "    Y.append(data[i + seq_len])\n",
    "\n",
    "X = torch.tensor(np.array(X), dtype=torch.float32).unsqueeze(-1) # (batch, seq, 1)\n",
    "Y = torch.tensor(np.array(Y), dtype=torch.float32).unsqueeze(-1) # (batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb197c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(1, 32, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, h = self.rnn(x)\n",
    "        return self.fc(h[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcffc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config=None):\n",
    "    global X, Y\n",
    "    # Initialize W&B\n",
    "    wandb_run = wandb.init(\n",
    "        project=\"VICI_test\",\n",
    "        entity=\"fabian-dubach-hochschule-luzern\",\n",
    "        config=config\n",
    "    )\n",
    "    config = wandb.config\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Starting run with config:\")\n",
    "    for k, v in dict(config).items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    # Setup Training\n",
    "    model = SineRNN() # Using the SineRNN class defined previously\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(\"Model moved to GPU.\")\n",
    "    X = X.to(device)\n",
    "    Y = Y.to(device)\n",
    "    print(\"X and Y moved to GPU.\")\n",
    "\n",
    "    # Training Loop\n",
    "    print(\"Starting Test Run...\")\n",
    "    for epoch in range(config['epochs']):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X) # Ensure X and Y are defined in your global scope\n",
    "        loss = criterion(output, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"learning_rate\": config['learning_rate'],\n",
    "            \"loss\": loss.item()\n",
    "        })\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # --- SAVE CHECKPOINT ---\n",
    "    checkpoint_path = \"latest_model.pth\"\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"\\nModel saved to {checkpoint_path}\")\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training\n",
    "train_config = {\"learning_rate\": 0.01, \"epochs\": 20}\n",
    "train_model(config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0389441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the architecture again\n",
    "test_model = SineRNN()\n",
    "\n",
    "# 2. Load the saved weights\n",
    "test_model.load_state_dict(torch.load(\"latest_model.pth\", weights_only=True))\n",
    "test_model = test_model.to(device)\n",
    "test_model.eval() # Set to evaluation mode\n",
    "\n",
    "# 3. Run a quick test prediction\n",
    "with torch.no_grad():\n",
    "    sample_input = X[:1] # Take the first sequence from your data\n",
    "    prediction = test_model(sample_input)\n",
    "    \n",
    "    print(\"Checkpoint Test:\")\n",
    "    print(f\"Input Sequence Shape: {sample_input.shape}\")\n",
    "    print(f\"Predicted Value: {prediction.item():.4f}\")\n",
    "    print(f\"Actual Value:    {Y[0].item():.4f}\")\n",
    "    print(\"\\nCheckpoint successfully loaded and verified!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
